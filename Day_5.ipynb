{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdQwIjDkrxYGxuVlsac28N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshaVardhanLanka/springboard_project/blob/main/Day_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QccE5sMQ-CBO"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from tavily import TavilyClient\n",
        "from google.colab import userdata\n",
        "\n",
        "# 1. Setup API Keys\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    TAVILY_API_KEY = userdata.get('TAVILY')\n",
        "except:\n",
        "    print(\"Error: Please set your API keys in the Colab Secrets tab (Key icon on the left).\")\n",
        "\n",
        "# 2. Configure Gemini\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro-latest') # Updated to gemini-pro-latest\n",
        "\n",
        "# 3. Configure Tavily\n",
        "tavily = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "\n",
        "print(\"Setup complete! Ready to research.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwk3kVb4-eAB",
        "outputId": "7f78316e-0fc2-4d0d-b878-d50041990168"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete! Ready to research.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sub_questions(topic):\n",
        "    \"\"\"Step 1: Decompose the topic into sub-questions using Gemini\"\"\"\n",
        "    print(f\"ü§î Generating sub-questions for: {topic}...\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a research assistant. Break down the following topic into 3 distinct,\n",
        "    searchable sub-questions to gather comprehensive information.\n",
        "\n",
        "    Topic: {topic}\n",
        "\n",
        "    Output format: Return ONLY the 3 questions separated by newlines.\n",
        "    Do not number them. Do not add introductory text.\n",
        "    \"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    # Clean up the text to get a list of questions\n",
        "    questions = [q.strip() for q in response.text.strip().split('\\n') if q.strip()]\n",
        "\n",
        "    return questions[:3] # Ensure we only return 3\n",
        "\n",
        "def perform_research(questions):\n",
        "    \"\"\"Step 2: Search Tavily for each question\"\"\"\n",
        "    print(f\"üîé Searching the web for answers...\")\n",
        "    research_data = []\n",
        "\n",
        "    for q in questions:\n",
        "        print(f\"   - Searching: {q}\")\n",
        "        # usage of tavily search\n",
        "        response = tavily.search(query=q, search_depth=\"basic\", max_results=1)\n",
        "\n",
        "        if response['results']:\n",
        "            content = response['results'][0]['content']\n",
        "            research_data.append(f\"Question: {q}\\nFound Info: {content}\")\n",
        "        else:\n",
        "            research_data.append(f\"Question: {q}\\nFound Info: No relevant info found.\")\n",
        "\n",
        "    return \"\\n\\n\".join(research_data)\n",
        "\n",
        "def synthesize_report(topic, research_data):\n",
        "    \"\"\"Step 3: Summarize everything into a final paragraph\"\"\"\n",
        "    print(f\"üìù Synthesizing final report...\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a professional researcher. Based ONLY on the provided research data below,\n",
        "    write a concise, high-quality paragraph summarizing the findings regarding the topic: \"{topic}\".\n",
        "\n",
        "    Research Data:\n",
        "    {research_data}\n",
        "\n",
        "    Final Summary:\n",
        "    \"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "flLCN79W-ptp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Workflow ---\n",
        "\n",
        "# 1. Take User Input\n",
        "user_topic = input(\"Enter a research topic (e.g., 'The future of solid state batteries'): \")\n",
        "\n",
        "if user_topic:\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # 2. Plan (Generate Questions)\n",
        "    sub_questions = generate_sub_questions(user_topic)\n",
        "    print(f\"Generated Questions: {sub_questions}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # 3. Act (Search)\n",
        "    raw_data = perform_research(sub_questions)\n",
        "    # Optional: Print raw data to see what the agent found\n",
        "    # print(f\"Raw Data:\\n{raw_data}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # 4. Synthesize (Final Output)\n",
        "    final_summary = synthesize_report(user_topic, raw_data)\n",
        "\n",
        "    print(\"\\nüéØ FINAL RESEARCH SUMMARY:\\n\")\n",
        "    print(final_summary)\n",
        "else:\n",
        "    print(\"Please enter a valid topic.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "dIeMoCdg-0aX",
        "outputId": "40276ad7-44b7-449e-b5fe-db46fd473659"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a research topic (e.g., 'The future of solid state batteries'): Detecting Ocular Toxoplasmosis in eye using XAi\n",
            "--------------------------------------------------\n",
            "ü§î Generating sub-questions for: Detecting Ocular Toxoplasmosis in eye using XAi...\n",
            "Generated Questions: ['What specific XAI techniques and deep learning models are most effective for identifying key biomarkers of ocular toxoplasmosis from retinal fundus images?', \"How do explainable AI (XAI) heatmaps and feature attribution methods improve ophthalmologists' diagnostic confidence and accuracy in differentiating ocular toxoplasmosis from other posterior uveitis mimics?\", 'What are the primary challenges, including data heterogeneity and model generalizability, in developing and clinically validating XAI systems for the automated diagnosis of active versus scarred ocular toxoplasmosis lesions?']\n",
            "--------------------------------------------------\n",
            "üîé Searching the web for answers...\n",
            "   - Searching: What specific XAI techniques and deep learning models are most effective for identifying key biomarkers of ocular toxoplasmosis from retinal fundus images?\n",
            "   - Searching: How do explainable AI (XAI) heatmaps and feature attribution methods improve ophthalmologists' diagnostic confidence and accuracy in differentiating ocular toxoplasmosis from other posterior uveitis mimics?\n",
            "   - Searching: What are the primary challenges, including data heterogeneity and model generalizability, in developing and clinically validating XAI systems for the automated diagnosis of active versus scarred ocular toxoplasmosis lesions?\n",
            "--------------------------------------------------\n",
            "üìù Synthesizing final report...\n",
            "\n",
            "üéØ FINAL RESEARCH SUMMARY:\n",
            "\n",
            "Based on the provided research data, deep learning models are being proposed for the automatic diagnosis of ocular toxoplasmosis using eye fundus images, with the goal of enhancing diagnostic accuracy over traditional methods. These systems have been evaluated on cloud platforms such as AWS and Google Cloud (Vertex AI). However, a significant challenge in developing these clinical AI tools is model generalization, as biases in training data can lead to inaccurate predictions and serious negative consequences for patients. The research highlights this as a fundamental machine learning problem, pointing toward the need for principled algorithmic approaches and further study into generalization within the small sample sizes typical of clinical applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vR1bYfDvB-F3"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}