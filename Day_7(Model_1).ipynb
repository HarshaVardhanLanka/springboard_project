{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOOBi/QWYdH3HoxcZw2JeSw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshaVardhanLanka/OpenDeepResearchAgent/blob/main/Day_7(Model_1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXBhtK_IrETa",
        "outputId": "3344edd4-285d-496b-bb15-b36132649010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/329.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m327.7/329.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai tavily-python pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import json\n",
        "import datetime\n",
        "import google.generativeai as genai\n",
        "from tavily import TavilyClient\n",
        "from google.colab import userdata\n",
        "from google.colab import files\n",
        "import pypdf\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# --- API CONFIGURATION ---\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    TAVILY_API_KEY = userdata.get('TAVILY')\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Error: Please set GOOGLE_API_KEY and TAVILY_API_KEY in Colab Secrets.\")\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro-latest')\n",
        "tavily = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "print(\"Setup complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-WXYA3vrFV9",
        "outputId": "d31fe99a-bcdd-4ba4-8451-1304c1017480"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MEMORY SYSTEM ---\n",
        "class HistoryManager:\n",
        "    def __init__(self):\n",
        "        self.history_file = \"agent_history.json\"\n",
        "        self.history = self.load_history()\n",
        "\n",
        "    def load_history(self):\n",
        "        \"\"\"Loads history from a JSON file if it exists.\"\"\"\n",
        "        if os.path.exists(self.history_file):\n",
        "            with open(self.history_file, 'r') as f:\n",
        "                return json.load(f)\n",
        "        return []\n",
        "\n",
        "    def save_entry(self, input_text, mode, final_report):\n",
        "        \"\"\"Saves a new research session to memory.\"\"\"\n",
        "        entry = {\n",
        "            \"id\": len(self.history) + 1,\n",
        "            \"timestamp\": str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")),\n",
        "            \"mode\": mode,\n",
        "            \"input\": input_text[:15] + \"...\" if len(input_text) > 50 else input_text, # Preview only\n",
        "            \"full_input\": input_text,\n",
        "            \"report\": final_report\n",
        "        }\n",
        "        self.history.append(entry)\n",
        "        with open(self.history_file, 'w') as f:\n",
        "            json.dump(self.history, f)\n",
        "        print(\"‚úÖ Research saved to History.\")\n",
        "\n",
        "    def show_history(self):\n",
        "        \"\"\"Displays list of past inputs.\"\"\"\n",
        "        if not self.history:\n",
        "            print(\"\\nüì≠ History is empty.\")\n",
        "            return None\n",
        "\n",
        "        print(\"\\nüìö RESEARCH HISTORY:\")\n",
        "        print(f\"{'ID':<4} | {'Time':<18} | {'Mode':<8} | {'Topic/Input'}\")\n",
        "        print(\"-\" * 60)\n",
        "        for item in self.history:\n",
        "            print(f\"{item['id']:<4} | {item['timestamp']:<18} | {item['mode']:<8} | {item['input']}\")\n",
        "        return self.history\n",
        "# Initialize Memory\n",
        "memory = HistoryManager()\n",
        "\n",
        "# --- HELPER: PDF TEXT EXTRACTOR ---\n",
        "def extract_pdf_text(uploaded_file_bytes):\n",
        "    try:\n",
        "        pdf_reader = pypdf.PdfReader(io.BytesIO(uploaded_file_bytes))\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {e}\"\n",
        "\n",
        "# --- STRICT AGENT STEPS ---\n",
        "\n",
        "def step_1_generate_questions(input_text, mode):\n",
        "    \"\"\"Generates 3 questions based on mode.\"\"\"\n",
        "    print(f\"\\nStep 1: Generating 3 sub-questions (Mode: {mode})...\")\n",
        "\n",
        "    if mode == \"topic\":\n",
        "        prompt = f\"\"\"\n",
        "        Task: Break down the topic \"{input_text}\" into exactly 3 searchable questions.\n",
        "        Constraint: Output ONLY the 3 questions separated by newlines. No numbering.\n",
        "        \"\"\"\n",
        "    else: # mode == pdf\n",
        "        prompt = f\"\"\"\n",
        "        Task: Read the following paper excerpt and generate 3 search questions to VALIDATE the claims or check for newer updates.\n",
        "        Paper Context: {input_text[:10000]}\n",
        "        Constraint: Output ONLY the 3 questions separated by newlines. No numbering.\n",
        "        \"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    questions = [q.strip() for q in response.text.strip().split('\\n') if q.strip()]\n",
        "    return questions[:3]\n",
        "\n",
        "def step_2_get_responses(questions):\n",
        "    \"\"\"Retrieves short responses (Max 1 result per question).\"\"\"\n",
        "    print(f\"Step 2: Retrieving short responses from the web...\")\n",
        "    q_and_a_results = []\n",
        "\n",
        "    for i, q in enumerate(questions, 1):\n",
        "        print(f\"   {i}. Searching: {q}\")\n",
        "        try:\n",
        "            # max_results=1 forces a short response\n",
        "            search_result = tavily.search(query=q, search_depth=\"basic\", max_results=1)\n",
        "\n",
        "            if search_result['results']:\n",
        "                content = search_result['results'][0]['content'][:600] # Limit char count\n",
        "                q_and_a_results.append(f\"Question: {q}\\nFound Info: {content}\")\n",
        "            else:\n",
        "                q_and_a_results.append(f\"Question: {q}\\nFound Info: No data.\")\n",
        "        except:\n",
        "             q_and_a_results.append(f\"Question: {q}\\nFound Info: Search Failed.\")\n",
        "\n",
        "    return \"\\n---\\n\".join(q_and_a_results)\n",
        "\n",
        "def step_3_summarize(input_text, research_data, mode=\"topic\"):\n",
        "    \"\"\"Summarizes everything into a final report.\"\"\"\n",
        "    print(f\"üìù Synthesizing final report...\")\n",
        "\n",
        "    if mode == \"topic\":\n",
        "        prompt = f\"\"\"\n",
        "        Write a comprehensive research summary on the topic below, incorporating the search findings.\n",
        "\n",
        "        User Topic: {input_text}\n",
        "        Search Data: {research_data}\n",
        "\n",
        "        Format: Markdown with headers.\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"\n",
        "        Create a \"Deep Dive\" analysis of the provided research paper using the external search data.\n",
        "\n",
        "        1. Summarize the Paper's core contribution.\n",
        "        2. Compare it with the \"External Validation\" findings (State-of-the-art, updates, or contradictions).\n",
        "        3. Provide a final conclusion on the paper's relevance today.\n",
        "\n",
        "        Paper Text (Context): {input_text[:15000]}\n",
        "        External Validation Data: {research_data}\n",
        "\n",
        "        Format: Markdown with headers.\n",
        "        \"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    if not response.candidates:\n",
        "        feedback = response.prompt_feedback\n",
        "        error_message = f\"Model did not return any candidates. Finish reason: {feedback.finish_reason}. Safety ratings: {feedback.safety_ratings}\"\n",
        "        print(f\"Error: {error_message}\")\n",
        "        return f\"**Error generating report:** {error_message}\"\n",
        "    try:\n",
        "        return response.text\n",
        "    except ValueError as e:\n",
        "        feedback = response.prompt_feedback\n",
        "        error_message = f\"Failed to access response.text: {e}. Finish reason: {feedback.finish_reason}. Safety ratings: {feedback.safety_ratings}\"\n",
        "        print(f\"Error: {error_message}\")\n",
        "        return f\"**Error generating report:** {error_message}\""
      ],
      "metadata": {
        "id": "WrXniAQvrTEj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MAIN LOOP ---\n",
        "\n",
        "def main():\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\"*15 + \" STRICT HYBRID AGENT \" + \"=\"*15)\n",
        "        print(\"1. Research a Topic (Text üí¨)\")\n",
        "        print(\"2. Research a Paper (Upload PDF üìñ)\")\n",
        "        print(\"3. View History üìú\")\n",
        "        print(\"4. Exit üì§\")\n",
        "\n",
        "        choice = input(\"Select Option: \")\n",
        "\n",
        "        if choice == '4':\n",
        "            print(\"Goodbye.üëã\")\n",
        "            break\n",
        "\n",
        "        # --- OPTION 3: HISTORY ---\n",
        "        if choice == '3':\n",
        "            history_data = memory.show_history()\n",
        "            if history_data:\n",
        "                sub_choice = input(\"\\nEnter ID to view full report (or Press Enter to go back): \")\n",
        "                if sub_choice.isdigit():\n",
        "                    idx = int(sub_choice) - 1\n",
        "                    if 0 <= idx < len(history_data):\n",
        "                        entry = history_data[idx]\n",
        "                        print(f\"\\nüîÅ RECALLING REPORT FOR: {entry['input']}\")\n",
        "                        print(\"-\" * 50)\n",
        "                        display(Markdown(entry['report']))\n",
        "                        input(\"\\nPress Enter to continue...\")\n",
        "            continue # Skip the rest and go back to menu\n",
        "\n",
        "        # SETUP INPUT\n",
        "        mode = \"\"\n",
        "        input_data = \"\"\n",
        "        label = \"\" # Used for history title\n",
        "\n",
        "        if choice == '1':\n",
        "            mode = \"topic\"\n",
        "            input_data = input(\"\\nEnter Research Topic: \")\n",
        "            label = input_data\n",
        "\n",
        "        elif choice == '2':\n",
        "            mode = \"pdf\"\n",
        "            print(\"\\n‚¨ÜÔ∏è Upload PDF now:\")\n",
        "            uploaded = files.upload()\n",
        "            if uploaded:\n",
        "                filename = next(iter(uploaded))\n",
        "                input_data = extract_pdf_text(uploaded[filename])\n",
        "                label = f\"PDF: {filename}\"\n",
        "            else:\n",
        "                print(\"No file uploaded.\")\n",
        "                continue\n",
        "\n",
        "        if input_data:\n",
        "            # --- EXECUTE 3-STEP PROCESS ---\n",
        "\n",
        "            # 1. Generate Questions\n",
        "            questions = step_1_generate_questions(input_data, mode)\n",
        "            print(f\"   -> Plan: {questions}\")\n",
        "\n",
        "            # 2. Retrieve Responses\n",
        "            raw_data = step_2_get_responses(questions)\n",
        "\n",
        "            # 3. Summarize\n",
        "            final_report = step_3_summarize(input_data, raw_data, mode)\n",
        "\n",
        "            print(\"\\n\" + \"=\"*20 + \" üéØ FINAL REPORT: \" + \"=\"*20 + \"\\n\")\n",
        "            display(Markdown(final_report))\n",
        "\n",
        "            # Save to History\n",
        "            memory.save_entry(label, mode, final_report)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T6nFrBJ5rYFz",
        "outputId": "6ecf3ab4-36c4-40b6-e851-f2071b754303"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=============== STRICT HYBRID AGENT ===============\n",
            "1. Research a Topic (Text üí¨)\n",
            "2. Research a Paper (Upload PDF üìñ)\n",
            "3. View History üìú\n",
            "4. Exit üì§\n",
            "Select Option: 3\n",
            "\n",
            "üìö RESEARCH HISTORY:\n",
            "ID   | Time               | Mode     | Topic/Input\n",
            "------------------------------------------------------------\n",
            "1    | 2025-11-27 12:36   | pdf      | PDF: 2511.17546v1.pdf\n",
            "\n",
            "Enter ID to view full report (or Press Enter to go back): 1\n",
            "\n",
            "üîÅ RECALLING REPORT FOR: PDF: 2511.17546v1.pdf\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here is a \"Deep Dive\" analysis of the research paper by Rathi et al. based on the provided text and external validation data.\n\n***\n\n### Deep Dive: Reference Quadrupole Moments from Muonic Atom Lamb Shifts\n\n#### 1. Paper's Core Contribution\n\nThe research paper by Rathi et al. proposes a novel experimental method to significantly improve the accuracy of absolute electric quadrupole moments (Q_ref) for light transition elements (Z=23 to 30, including V, Cr, Mn, Co, Ni, Cu, Zn).\n\nThe core contribution is the synergistic combination of three key elements to solve a long-standing measurement problem:\n\n1.  **Utilizing Muonic Atoms:** The paper circumvents the primary source of uncertainty in current Q_ref measurements: the complex and often unreliable theoretical calculations of the Electric Field Gradient (EFG) in many-electron atoms. By replacing an electron with a much heavier muon, the system becomes hydrogen-like, making the EFG straightforward to calculate with high accuracy (~1%). Furthermore, the quadrupole interaction is enhanced by a factor of ~10‚Å∑, making the effect much larger and easier to measure.\n\n2.  **Focusing on a Specific Transition:** The authors identify the weakly populated muonic 2s ‚Üí 2p transition (the Lamb shift) as the ideal target. The hyperfine splitting of the 2p level in this transition is directly proportional to the nuclear quadrupole moment.\n\n3.  **Employing Cryogenic Microcalorimeters (MCs):** This is the key technological enabler. Previous attempts to use muonic atoms in this Z-range were stymied by detector limitations. The 2s ‚Üí 2p transitions are too weak for low-efficiency crystal spectrometers and their energy splitting is too small to be resolved by conventional solid-state detectors. The paper argues that modern MCs possess the unique combination of high quantum efficiency and excellent energy resolution (~10 eV) required to resolve the hyperfine structure of these transitions in the 10-40 keV range.\n\nThe paper presents a detailed feasibility study for ‚Å∂¬≥Cu, including GEANT4 simulations to optimize muon beam momentum and cascade calculations to estimate signal rates. The authors conclude that their proposed method can reduce the uncertainty in Q_ref by up to an order of magnitude within a single day of measurement, providing a crucial benchmark for nuclear physics and quantum chemistry.\n\n#### 2. Comparison with External Validation Findings\n\nThe external data provides strong validation and even enhances the prospects of the proposed method.\n\n*   **On Theoretical Foundations:** The first external data point mentions the use of the \"Multiconfiguration Dirac-Fock and General Matrix Elements Program (MCDFGME)\" and \"leading order QED corrections,\" referencing one of the paper's authors (Indelicato). This directly **confirms** that the theoretical framework used in the paper for calculating muonic energy levels and transition rates is indeed state-of-the-art and aligns with the accepted high-precision computational methods in the field.\n\n*   **On the Problem's Significance:** The second data point, discussing EFG calculations for Antimony clusters, indirectly **reinforces** the paper's premise. It shows that EFG calculation remains an active and system-specific research area. The fact that calculations are still being developed for different elements and configurations underscores the difficulty of achieving high accuracy universally, especially for the challenging open d-shell elements the paper targets. This validates the paper's motivation for pursuing a method that is largely independent of complex EFG calculations in many-electron systems.\n\n*   **On Technological Feasibility (State-of-the-art Update):** The third external data point is the most significant. The paper bases its feasibility calculations on an MC resolution of \"‚âà10 eV\". The external finding reports the development of a TES microcalorimeter with an energy resolution of **3.1 - 4 eV FWHM**. This is a major **positive update**.\n    *   **Contradiction:** There is no contradiction; rather, this shows rapid progress in the field.\n    *   **Update:** The available detector technology is now 2-3 times better than the conservative estimate used in the paper's simulations. This dramatically strengthens the paper's proposal. A detector with ~3 eV resolution would resolve the hyperfine splitting (which is on the order of hundreds of eV, as seen in Table I) with much greater clarity, reducing statistical uncertainty, shortening the required measurement time, and potentially allowing for the measurement of even smaller effects or weaker transitions.\n\n#### 3. Final Conclusion on the Paper's Relevance Today\n\nThe paper by Rathi et al. is **highly relevant and forward-looking**. It is not a report of a completed experiment but a compelling and well-researched proposal that charts a clear path to solving a significant problem in fundamental physics.\n\n1.  **Addresses a Critical Gap:** The paper correctly identifies a \"gap\" in the nuclear chart where reference quadrupole moments for transition metals are poorly known due to the limitations of existing methods. Improving these Q_ref values would have a cascading effect, refining the moments for entire isotopic chains and providing stringent tests for nuclear structure theories that model nuclear deformation.\n\n2.  **Methodologically Sound and Innovative:** The proposed combination of muonic atoms and cryogenic microcalorimeters is innovative and expertly tailored to the problem. It cleverly leverages the unique properties of muons to create a \"clean\" system for measurement while harnessing the latest advances in detector technology to make that measurement possible.\n\n3.  **Strengthened by Current Technology:** As confirmed by the external data, the technological premise of the paper is not just sound but has been surpassed. The availability of detectors with 3-4 eV resolution makes the proposed experiment more feasible and potentially more precise than the authors originally projected.\n\nIn conclusion, this paper serves as an essential blueprint for future experiments at muon facilities like the Paul Scherrer Institute (PSI). Its relevance lies in its potential to unlock a new tier of precision in nuclear moments for a crucial set of elements, thereby providing benchmark data that will be invaluable to both nuclear physicists and quantum chemists for years to come. The work is a prime example of how advances in instrumentation can reopen and solve long-standing fundamental questions."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Press Enter to continue...\n",
            "\n",
            "=============== STRICT HYBRID AGENT ===============\n",
            "1. Research a Topic (Text üí¨)\n",
            "2. Research a Paper (Upload PDF üìñ)\n",
            "3. View History üìú\n",
            "4. Exit üì§\n",
            "Select Option: 4\n",
            "Goodbye.üëã\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j8LoTe7ErcK0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}