{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOBi/QWYdH3HoxcZw2JeSw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshaVardhanLanka/OpenDeepResearchAgent/blob/main/Day_7(Model_1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXBhtK_IrETa",
        "outputId": "764bfb61-95ee-414e-ad74-eb9444f199dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/329.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m327.7/329.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai tavily-python pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import json\n",
        "import datetime\n",
        "import google.generativeai as genai\n",
        "from tavily import TavilyClient\n",
        "from google.colab import userdata\n",
        "from google.colab import files\n",
        "import pypdf\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# --- API CONFIGURATION ---\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    TAVILY_API_KEY = userdata.get('TAVILY')\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Error: Please set GOOGLE_API_KEY and TAVILY_API_KEY in Colab Secrets.\")\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro-latest')\n",
        "tavily = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "print(\"Setup complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-WXYA3vrFV9",
        "outputId": "3e5272ec-738d-4e9b-ca08-4b5680dfff4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MEMORY SYSTEM ---\n",
        "class HistoryManager:\n",
        "    def __init__(self):\n",
        "        self.history_file = \"agent_history.json\"\n",
        "        self.history = self.load_history()\n",
        "\n",
        "    def load_history(self):\n",
        "        \"\"\"Loads history from a JSON file if it exists.\"\"\"\n",
        "        if os.path.exists(self.history_file):\n",
        "            with open(self.history_file, 'r') as f:\n",
        "                return json.load(f)\n",
        "        return []\n",
        "\n",
        "    def save_entry(self, input_text, mode, final_report):\n",
        "        \"\"\"Saves a new research session to memory.\"\"\"\n",
        "        entry = {\n",
        "            \"id\": len(self.history) + 1,\n",
        "            \"timestamp\": str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")),\n",
        "            \"mode\": mode,\n",
        "            \"input\": input_text[:15] + \"...\" if len(input_text) > 50 else input_text, # Preview only\n",
        "            \"full_input\": input_text,\n",
        "            \"report\": final_report\n",
        "        }\n",
        "        self.history.append(entry)\n",
        "        with open(self.history_file, 'w') as f:\n",
        "            json.dump(self.history, f)\n",
        "        print(\"‚úÖ Research saved to History.\")\n",
        "\n",
        "    def show_history(self):\n",
        "        \"\"\"Displays list of past inputs.\"\"\"\n",
        "        if not self.history:\n",
        "            print(\"\\nüì≠ History is empty.\")\n",
        "            return None\n",
        "\n",
        "        print(\"\\nüìö RESEARCH HISTORY:\")\n",
        "        print(f\"{'ID':<4} | {'Time':<18} | {'Mode':<8} | {'Topic/Input'}\")\n",
        "        print(\"-\" * 60)\n",
        "        for item in self.history:\n",
        "            print(f\"{item['id']:<4} | {item['timestamp']:<18} | {item['mode']:<8} | {item['input']}\")\n",
        "        return self.history\n",
        "# Initialize Memory\n",
        "memory = HistoryManager()\n",
        "\n",
        "# --- HELPER: PDF TEXT EXTRACTOR ---\n",
        "def extract_pdf_text(uploaded_file_bytes):\n",
        "    try:\n",
        "        pdf_reader = pypdf.PdfReader(io.BytesIO(uploaded_file_bytes))\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {e}\"\n",
        "\n",
        "# --- STRICT AGENT STEPS ---\n",
        "\n",
        "def step_1_generate_questions(input_text, mode):\n",
        "    \"\"\"Generates 3 questions based on mode.\"\"\"\n",
        "    print(f\"\\nStep 1: Generating 3 sub-questions (Mode: {mode})...\")\n",
        "\n",
        "    if mode == \"topic\":\n",
        "        prompt = f\"\"\"\n",
        "        Task: Break down the topic \"{input_text}\" into exactly 3 searchable questions.\n",
        "        Constraint: Output ONLY the 3 questions separated by newlines. No numbering.\n",
        "        \"\"\"\n",
        "    else: # mode == pdf\n",
        "        prompt = f\"\"\"\n",
        "        Task: Read the following paper excerpt and generate 3 search questions to VALIDATE the claims or check for newer updates.\n",
        "        Paper Context: {input_text[:10000]}\n",
        "        Constraint: Output ONLY the 3 questions separated by newlines. No numbering.\n",
        "        \"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    questions = [q.strip() for q in response.text.strip().split('\\n') if q.strip()]\n",
        "    return questions[:3]\n",
        "\n",
        "def step_2_get_responses(questions):\n",
        "    \"\"\"Retrieves short responses (Max 1 result per question).\"\"\"\n",
        "    print(f\"Step 2: Retrieving short responses from the web...\")\n",
        "    q_and_a_results = []\n",
        "\n",
        "    for i, q in enumerate(questions, 1):\n",
        "        print(f\"   {i}. Searching: {q}\")\n",
        "        try:\n",
        "            # max_results=1 forces a short response\n",
        "            search_result = tavily.search(query=q, search_depth=\"basic\", max_results=1)\n",
        "\n",
        "            if search_result['results']:\n",
        "                content = search_result['results'][0]['content'][:600] # Limit char count\n",
        "                q_and_a_results.append(f\"Question: {q}\\nFound Info: {content}\")\n",
        "            else:\n",
        "                q_and_a_results.append(f\"Question: {q}\\nFound Info: No data.\")\n",
        "        except:\n",
        "             q_and_a_results.append(f\"Question: {q}\\nFound Info: Search Failed.\")\n",
        "\n",
        "    return \"\\n---\\n\".join(q_and_a_results)\n",
        "\n",
        "def step_3_summarize(input_text, research_data, mode=\"topic\"):\n",
        "    \"\"\"Summarizes everything into a final report.\"\"\"\n",
        "    print(f\"üìù Synthesizing final report...\")\n",
        "\n",
        "    if mode == \"topic\":\n",
        "        prompt = f\"\"\"\n",
        "        Write a comprehensive research summary on the topic below, incorporating the search findings.\n",
        "\n",
        "        User Topic: {input_text}\n",
        "        Search Data: {research_data}\n",
        "\n",
        "        Format: Markdown with headers.\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"\n",
        "        Create a \"Deep Dive\" analysis of the provided research paper using the external search data.\n",
        "\n",
        "        1. Summarize the Paper's core contribution.\n",
        "        2. Compare it with the \"External Validation\" findings (State-of-the-art, updates, or contradictions).\n",
        "        3. Provide a final conclusion on the paper's relevance today.\n",
        "\n",
        "        Paper Text (Context): {input_text[:15000]}\n",
        "        External Validation Data: {research_data}\n",
        "\n",
        "        Format: Markdown with headers.\n",
        "        \"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    if not response.candidates:\n",
        "        feedback = response.prompt_feedback\n",
        "        error_message = f\"Model did not return any candidates. Finish reason: {feedback.finish_reason}. Safety ratings: {feedback.safety_ratings}\"\n",
        "        print(f\"Error: {error_message}\")\n",
        "        return f\"**Error generating report:** {error_message}\"\n",
        "    try:\n",
        "        return response.text\n",
        "    except ValueError as e:\n",
        "        feedback = response.prompt_feedback\n",
        "        error_message = f\"Failed to access response.text: {e}. Finish reason: {feedback.finish_reason}. Safety ratings: {feedback.safety_ratings}\"\n",
        "        print(f\"Error: {error_message}\")\n",
        "        return f\"**Error generating report:** {error_message}\""
      ],
      "metadata": {
        "id": "WrXniAQvrTEj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MAIN LOOP ---\n",
        "\n",
        "def main():\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\"*15 + \" STRICT HYBRID AGENT \" + \"=\"*15)\n",
        "        print(\"1. Research a Topic (Text üí¨)\")\n",
        "        print(\"2. Research a Paper (Upload PDF üìñ)\")\n",
        "        print(\"3. View History üìú\")\n",
        "        print(\"4. Exit üì§\")\n",
        "\n",
        "        choice = input(\"Select Option: \")\n",
        "\n",
        "        if choice == '4':\n",
        "            print(\"Goodbye.üëã\")\n",
        "            break\n",
        "\n",
        "        # --- OPTION 3: HISTORY ---\n",
        "        if choice == '3':\n",
        "            history_data = memory.show_history()\n",
        "            if history_data:\n",
        "                sub_choice = input(\"\\nEnter ID to view full report (or Press Enter to go back): \")\n",
        "                if sub_choice.isdigit():\n",
        "                    idx = int(sub_choice) - 1\n",
        "                    if 0 <= idx < len(history_data):\n",
        "                        entry = history_data[idx]\n",
        "                        print(f\"\\nüîÅ RECALLING REPORT FOR: {entry['input']}\")\n",
        "                        print(\"-\" * 50)\n",
        "                        display(Markdown(entry['report']))\n",
        "                        input(\"\\nPress Enter to continue...\")\n",
        "            continue # Skip the rest and go back to menu\n",
        "\n",
        "        # SETUP INPUT\n",
        "        mode = \"\"\n",
        "        input_data = \"\"\n",
        "        label = \"\" # Used for history title\n",
        "\n",
        "        if choice == '1':\n",
        "            mode = \"topic\"\n",
        "            input_data = input(\"\\nEnter Research Topic: \")\n",
        "            label = input_data\n",
        "\n",
        "        elif choice == '2':\n",
        "            mode = \"pdf\"\n",
        "            print(\"\\n‚¨ÜÔ∏è Upload PDF now:\")\n",
        "            uploaded = files.upload()\n",
        "            if uploaded:\n",
        "                filename = next(iter(uploaded))\n",
        "                input_data = extract_pdf_text(uploaded[filename])\n",
        "                label = f\"PDF: {filename}\"\n",
        "            else:\n",
        "                print(\"No file uploaded.\")\n",
        "                continue\n",
        "\n",
        "        if input_data:\n",
        "            # --- EXECUTE 3-STEP PROCESS ---\n",
        "\n",
        "            # 1. Generate Questions\n",
        "            questions = step_1_generate_questions(input_data, mode)\n",
        "            print(f\"   -> Plan: {questions}\")\n",
        "\n",
        "            # 2. Retrieve Responses\n",
        "            raw_data = step_2_get_responses(questions)\n",
        "\n",
        "            # 3. Summarize\n",
        "            final_report = step_3_summarize(input_data, raw_data, mode)\n",
        "\n",
        "            print(\"\\n\" + \"=\"*20 + \" üéØ FINAL REPORT: \" + \"=\"*20 + \"\\n\")\n",
        "            display(Markdown(final_report))\n",
        "\n",
        "            # Save to History\n",
        "            memory.save_entry(label, mode, final_report)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T6nFrBJ5rYFz",
        "outputId": "8f4f9371-c382-4791-fc2a-e08e962651cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=============== STRICT HYBRID AGENT ===============\n",
            "1. Research a Topic (Text üí¨)\n",
            "2. Research a Paper (Upload PDF üìñ)\n",
            "3. View History üìú\n",
            "4. Exit üì§\n",
            "Select Option: 3\n",
            "\n",
            "üìö RESEARCH HISTORY:\n",
            "ID   | Time               | Mode     | Topic/Input\n",
            "------------------------------------------------------------\n",
            "1    | 2025-11-26 15:03   | pdf      | PDF: 2511.17546v1.pdf\n",
            "\n",
            "Enter ID to view full report (or Press Enter to go back): 1\n",
            "\n",
            "üîÅ RECALLING REPORT FOR: PDF: 2511.17546v1.pdf\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here is a \"Deep Dive\" analysis of the research paper by Rathi et al. based on the provided text and external search data.\n\n***\n\n### Deep Dive: Reference Quadrupole Moments from Muonic Atom Lamb Shifts\n\n#### 1. Paper's Core Contribution\n\nThe paper by Rathi et al. proposes a novel experimental method to precisely measure the absolute electric quadrupole moments (Q) for a specific group of elements: the light transition metals (from Vanadium, Z=23 to Zinc, Z=30).\n\n**The Problem:** The accuracy of Q values for all isotopes of an element is limited by the precision of a single \"reference\" value, `Q_ref`, typically measured for a stable isotope. For transition metals, determining `Q_ref` is challenging. The standard method involves atomic spectroscopy, which requires highly accurate theoretical calculations of the Electric Field Gradient (EFG) at the nucleus. These calculations are notoriously difficult and uncertain for atoms with open d-shell electronic configurations, leading to large uncertainties in `Q_ref` for this region of the periodic table.\n\n**The Proposed Solution:** The authors advocate for using **muonic atoms** to bypass the problem of complex electronic structure calculations. In a muonic atom, a muon orbits the nucleus. Because a muon is ~200 times heavier than an electron, it orbits much closer to the nucleus, offering three key advantages:\n1.  **Massive EFG:** The EFG created by the muon is enormous (~10‚Å∑ times larger than from an electron), leading to large, measurable energy splittings.\n2.  **Simple Theory:** The EFG can be calculated with very high precision (<1%) because the muonic atom is a simple, hydrogen-like system, largely unaffected by the remaining atomic electrons.\n3.  **Clean Signal:** The quadrupole interaction dominates over the magnetic dipole interaction, simplifying the analysis.\n\n**The Innovation:** While using muonic atoms is not new, previous experiments were limited by detector technology. The authors propose measuring the weakly populated but highly sensitive **2s-2p Lamb shift transition** (in the 10-40 keV X-ray range) using **cryogenic microcalorimeters (MCs)**. These detectors provide the crucial combination of high energy resolution (~10 eV) and high efficiency necessary to resolve the hyperfine splitting of these faint transitions.\n\nThrough detailed simulations for `‚Å∂¬≥Cu`, the paper establishes the feasibility of this approach, demonstrating that it could improve the accuracy of `Q_ref` by up to an order of magnitude within a single day of measurement time at a facility like the Paul Scherrer Institute.\n\n#### 2. Comparison with External Validation Findings\n\nThis section compares the paper's claims and methods with the provided external search data, highlighting state-of-the-art updates and potential contradictions.\n\n**State-of-the-Art and Updates:**\n\n*   **Detector Technology (Validation):** The paper's entire premise relies on the performance of cryogenic microcalorimeters. The external data snippet mentioning the \"Development of cryogenic X-ray detectors based on Mo/Au TES\" (Transition-Edge Sensors) *strongly validates* the paper's technological foundation. It confirms that this detector technology is an active area of advanced research, with ongoing efforts to \"enable further enhancement of the achieved energy resolution.\" This suggests that the experimental conditions proposed by Rathi et al. are not only feasible but likely to improve, strengthening the paper's argument.\n\n*   **Competing Methodology (Update):** The paper argues that its muonic method is necessary because theoretical EFG calculations for transition metals are unreliable. However, the external data on `‚Å∂¬≥Cu` presents a significant update to this landscape. The finding that the `‚Å∂¬≥Cu` quadrupole moment was recently determined by combining experimental constants with \"relativistic Dirac-Coulomb coupled cluster calculations of the electric field gradient (EFG)\" shows that the *ab initio* theoretical approach has made substantial progress. This sophisticated computational method directly tackles the electronic correlation problem that the paper identifies as a major roadblock. This means the muonic atom method is no longer the *only* path forward; it is now in competition with a rapidly advancing theoretical front.\n\n**Contradictions:**\n\n*   **Premise of Necessity:** There is no direct contradiction of the physics presented in the paper. The advantages of muonic atoms are well-established. The \"contradiction\" is in the paper's underlying premise of *necessity*. The authors frame their method as a way to overcome a challenge that is \"poorly understood\" in conventional atomic systems. The external data on `‚Å∂¬≥Cu` suggests that this challenge, while difficult, is now being successfully met by cutting-edge quantum chemistry. Therefore, the muonic method's role may be shifting from a unique solution to a complementary benchmark.\n\n*   **Irrelevant Data:** The external data on \"Experimental Lamb-dip spectra\" in H‚ÇÇO is unrelated. It refers to a different physical phenomenon (molecular rovibrational transitions) and a different experimental technique (NICE-OHMS). It does not validate or contradict the paper's proposal concerning muonic atoms.\n\n#### 3. Final Conclusion on the Paper's Relevance Today\n\nThe paper by Rathi et al. remains highly relevant, though its role in the scientific landscape has evolved in light of recent progress in competing fields.\n\n1.  **Gold Standard Potential:** The proposed method is fundamentally robust. A measurement based on a simple, hydrogen-like muonic system is less susceptible to theoretical modeling errors than one relying on complex many-body electronic structure calculations. It therefore stands as a potential **\"gold standard\"** for determining `Q_ref`, providing a clean, experiment-driven value that is largely independent of atomic theory.\n\n2.  **Technological Timeliness:** The technological cornerstone of the proposal‚Äîcryogenic microcalorimetry‚Äîis more advanced today than at the time of writing, making the proposed experiment even more feasible.\n\n3.  **Crucial Benchmark:** Given the parallel advances in theoretical EFG calculations, the paper's proposed measurement has acquired a new and critical purpose: **to serve as a definitive benchmark.** If the muonic atom measurement of `Q_ref` for an element like `‚Å∂¬≥Cu` agrees with the value derived from the latest atomic coupled-cluster calculations, it would provide a powerful, cross-disciplinary validation of our understanding of relativistic quantum chemistry. If the values disagree, it would point to subtle, yet-unaccounted-for effects in either nuclear or atomic physics, stimulating new theoretical developments.\n\nIn conclusion, the paper outlines an elegant and powerful experimental approach. While no longer the only viable path to high-precision quadrupole moments for transition metals, it is arguably the cleanest. Its relevance today is as a crucial, first-principles benchmark that can be used to validate, challenge, and ultimately advance the state-of-the-art in both nuclear structure physics and theoretical atomic chemistry."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Press Enter to continue...\n",
            "\n",
            "=============== STRICT HYBRID AGENT ===============\n",
            "1. Research a Topic (Text üí¨)\n",
            "2. Research a Paper (Upload PDF üìñ)\n",
            "3. View History üìú\n",
            "4. Exit üì§\n",
            "Select Option: 2\n",
            "\n",
            "‚¨ÜÔ∏è Upload PDF now:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2b4cc5ae-e107-4678-a6ac-ddd76bf2454a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2b4cc5ae-e107-4678-a6ac-ddd76bf2454a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2511.17546v1.pdf to 2511.17546v1 (1).pdf\n",
            "\n",
            "Step 1: Generating 3 sub-questions (Mode: pdf)...\n",
            "   -> Plan: ['Recent advancements in cryogenic microcalorimeter performance for muonic x-ray spectroscopy in the 10-40 keV range.', 'Experimental realization of muonic Lamb shift measurements to determine quadrupole moments in transition elements.', 'Updated reference values for electric quadrupole moments of transition metals (Z=23-30) since 2016.']\n",
            "Step 2: Retrieving short responses from the web...\n",
            "   1. Searching: Recent advancements in cryogenic microcalorimeter performance for muonic x-ray spectroscopy in the 10-40 keV range.\n",
            "   2. Searching: Experimental realization of muonic Lamb shift measurements to determine quadrupole moments in transition elements.\n",
            "   3. Searching: Updated reference values for electric quadrupole moments of transition metals (Z=23-30) since 2016.\n",
            "üìù Synthesizing final report...\n",
            "\n",
            "==================== üéØ FINAL REPORT: ====================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### **Deep Dive Analysis: Reference Quadrupole Moments from Muonic Lamb Shifts**\n\nThis analysis examines the research paper by S. Rathi et al., which proposes a novel method for measuring nuclear electric quadrupole moments in transition elements, and evaluates its standing against external data.\n\n---\n\n#### **1. Paper's Core Contribution**\n\nThe core contribution of this paper is a **detailed feasibility study for a novel experimental method designed to significantly improve the accuracy of reference nuclear electric quadrupole moments (Q_ref) for light transition elements (Z=23 to Z=30).**\n\nThe authors identify a critical gap in nuclear data: the Q_ref values for elements like vanadium, chromium, manganese, and copper are poorly known. This is because traditional methods, which rely on atomic or molecular spectroscopy, are hampered by the immense difficulty of accurately calculating the electric field gradient (EFG) at the nucleus for elements with complex, open *d*-shell electronic configurations. Since the uncertainty in a single Q_ref propagates across the entire isotopic chain, this is a major limiting factor for nuclear structure studies.\n\nThe proposed solution is a synergy of two key components:\n\n1.  **Muonic Atoms:** By replacing electrons with muons, a hydrogen-like system is created. The muon's heavy mass (~207x the electron's) results in an orbit much closer to the nucleus. This has two profound advantages:\n    *   The EFG is enhanced by a factor of ~10‚Å∑, leading to large, easily measurable hyperfine splittings.\n    *   The system is theoretically \"clean.\" The EFG can be calculated with high precision, bypassing the complex electron correlation problems that plague normal atomic calculations.\n\n2.  **Cryogenic Microcalorimeters (MCs):** Previous attempts to use muonic atoms for this purpose were stalled by detector limitations. The crucial muonic transitions (specifically the 2s-2p Lamb shift) are weak and produce x-rays in the 10-40 keV range. Conventional solid-state detectors lack the resolution to distinguish the hyperfine structure, while high-resolution crystal spectrometers have extremely low efficiency, making the measurement of such weak signals impractical. The authors propose using MCs, which uniquely offer both **superb energy resolution (~10 eV)** and **high quantum efficiency** in this energy regime.\n\nThe paper's contribution is not an experimental result but a comprehensive theoretical and simulation-based argument (using MCDFGME and GEANT4) demonstrating that this experiment is viable. They calculate the expected signals, optimize experimental parameters like muon beam momentum, and show that an order-of-magnitude improvement in the accuracy of Q_ref is achievable within a reasonable measurement time (e.g., one day).\n\n---\n\n#### **2. Comparison with External Validation Findings**\n\nThe external search data provides strong validation for the paper's premises and highlights its continued relevance.\n\n*   **State-of-the-Art Confirmation:** The finding that *\"precision x-ray spectroscopy of exotic atoms is currently undergoing a paradigm shift due to the introduction of cryogenic microcalorimeter detectors\"* directly confirms the paper's central technological thesis. This external statement validates the authors' choice of MCs as a game-changing technology that makes their proposed measurement possible. It positions the paper not as a speculative idea but as one that leverages a cutting-edge, transformative tool in the field.\n\n*   **No Contradictions or Obsolescence:** The external search for updated quadrupole moments for the target elements (Z=23-30) did not return any new high-precision experimental values. The result for Praseodymium (Pr, Z=59) highlights that progress is being made elsewhere, but the specific \"problem region\" identified by Rathi et al. appears to remain unsolved. This **lack of new data strongly reinforces the paper's motivation.** It implies that no other competing technique has successfully addressed this challenge in the interim, making the proposed muonic atom experiment as necessary today as when it was proposed.\n\n*   **Methodological Soundness:** The mention of the MCDFGME program aligns perfectly with the methods detailed in the paper. This shows that the authors are using standard, state-of-the-art theoretical codes for their calculations, grounding their feasibility study in a robust computational framework recognized by the field.\n\nIn summary, the external data provides no contradictions. Instead, it confirms that the technological foundation of the proposal is sound and that the scientific problem it aims to solve remains a significant, open question in nuclear physics.\n\n---\n\n#### **3. Final Conclusion on the Paper's Relevance Today**\n\nThe paper by Rathi et al. is **highly relevant and forward-looking.** It acts as a crucial blueprint for a next-generation experiment poised to resolve a long-standing uncertainty in fundamental nuclear physics.\n\n1.  **Addresses a Persistent Problem:** The inaccuracies in Q_ref for transition metals are a known bottleneck that limits the interpretation of data from radioactive ion beam facilities and hinders the development of nuclear theory in this mass region. The paper offers a clear and viable path to breaking this deadlock.\n\n2.  **Proposes a Realistic Solution:** The relevance of the paper is amplified by the maturation of the proposed technology. As confirmed by the external data, cryogenic microcalorimeters are no longer a developmental curiosity but a paradigm-shifting tool. This makes the proposed experiment more feasible and timely than ever before.\n\n3.  **Impact Beyond Nuclear Physics:** Precise Q_ref values serve as critical benchmarks for state-of-the-art quantum chemistry calculations. By providing an unambiguous experimental value for the nuclear moment, this work would allow theorists to disentangle nuclear effects from electronic effects and rigorously test their complex computational models for open-shell systems.\n\nIn conclusion, this paper is not a historical artifact but a **well-defined and compelling research proposal.** Its value lies in its clear identification of a problem, its elegant combination of established physics (muonic atoms) with advanced technology (MCs), and its rigorous demonstration of feasibility. The work serves as a foundational document that will likely guide and justify future experimental efforts at facilities like the Paul Scherrer Institute (PSI). Its relevance will remain high until the proposed experiment is performed and the data gap it identifies is finally closed."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Research saved to History.\n",
            "\n",
            "=============== STRICT HYBRID AGENT ===============\n",
            "1. Research a Topic (Text üí¨)\n",
            "2. Research a Paper (Upload PDF üìñ)\n",
            "3. View History üìú\n",
            "4. Exit üì§\n",
            "Select Option: 4\n",
            "Goodbye.üëã\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j8LoTe7ErcK0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}