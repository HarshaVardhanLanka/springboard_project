{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfOhK4IxMiv16JYY/i5Bq+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshaVardhanLanka/OpenDeepResearchAgent/blob/main/Day_7(Model_2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt0OLEZ-YaCx",
        "outputId": "9d0749b5-32ff-4ea1-95e5-f89cc8ef4395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/329.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m276.5/329.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai tavily-python pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import json\n",
        "import datetime\n",
        "import google.generativeai as genai\n",
        "from tavily import TavilyClient\n",
        "from google.colab import userdata\n",
        "from google.colab import files\n",
        "import pypdf\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# --- API CONFIGURATION ---\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    TAVILY_API_KEY = userdata.get('TAVILY')\n",
        "except:\n",
        "    print(\"âš ï¸ Error: Please set GOOGLE_API_KEY and TAVILY_API_KEY in Colab Secrets.\")\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro-latest')\n",
        "tavily = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "print(\"Setup complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdWgMS-ZYo1h",
        "outputId": "a8984fb9-17db-4cfd-c8d1-77b3a853f8af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MEMORY SYSTEM ---\n",
        "class HistoryManager:\n",
        "    def __init__(self):\n",
        "        self.history_file = \"agent_history.json\"\n",
        "        self.history = self.load_history()\n",
        "\n",
        "    def load_history(self):\n",
        "        \"\"\"Loads history from a JSON file if it exists.\"\"\"\n",
        "        if os.path.exists(self.history_file):\n",
        "            with open(self.history_file, 'r') as f:\n",
        "                return json.load(f)\n",
        "        return []\n",
        "\n",
        "    def save_entry(self, input_text, mode, final_report):\n",
        "        \"\"\"Saves a new research session to memory.\"\"\"\n",
        "        entry = {\n",
        "            \"id\": len(self.history) + 1,\n",
        "            \"timestamp\": str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")),\n",
        "            \"mode\": mode,\n",
        "            \"input\": input_text[:15] + \"...\" if len(input_text) > 50 else input_text, # Preview only\n",
        "            \"full_input\": input_text,\n",
        "            \"report\": final_report\n",
        "        }\n",
        "        self.history.append(entry)\n",
        "        with open(self.history_file, 'w') as f:\n",
        "            json.dump(self.history, f)\n",
        "        print(\"âœ… Research saved to History.\")\n",
        "\n",
        "    def show_history(self):\n",
        "        \"\"\"Displays list of past inputs.\"\"\"\n",
        "        if not self.history:\n",
        "            print(\"\\nðŸ“­ History is empty.\")\n",
        "            return None\n",
        "\n",
        "        print(\"\\nðŸ“š RESEARCH HISTORY:\")\n",
        "        print(f\"{'ID':<4} | {'Time':<18} | {'Mode':<8} | {'Topic/Input'}\")\n",
        "        print(\"-\" * 60)\n",
        "        for item in self.history:\n",
        "            print(f\"{item['id']:<4} | {item['timestamp']:<18} | {item['mode']:<8} | {item['input']}\")\n",
        "        return self.history\n",
        "# Initialize Memory\n",
        "memory = HistoryManager()\n",
        "\n",
        "# --- HELPER: PDF TEXT EXTRACTOR ---\n",
        "def extract_pdf_text(uploaded_file_bytes):\n",
        "    try:\n",
        "        pdf_reader = pypdf.PdfReader(io.BytesIO(uploaded_file_bytes))\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {e}\"\n",
        "\n",
        "# --- STRICT AGENT STEPS ---\n",
        "\n",
        "def step_1_generate_questions(input_text, mode):\n",
        "    \"\"\"Generates 3 questions based on mode.\"\"\"\n",
        "    print(f\"\\nStep 1: Generating 3 sub-questions (Mode: {mode})...\")\n",
        "\n",
        "    if mode == \"topic\":\n",
        "        prompt = f\"\"\"\n",
        "        Task: Break down the topic \"{input_text}\" into exactly 3 searchable questions.\n",
        "        Constraint: Output ONLY the 3 questions separated by newlines. No numbering.\n",
        "        \"\"\"\n",
        "    else: # mode == pdf\n",
        "        prompt = f\"\"\"\n",
        "        Task: Read the following paper excerpt and generate 3 search questions to VALIDATE the claims or check for newer updates.\n",
        "        Paper Context: {input_text[:10000]}\n",
        "        Constraint: Output ONLY the 3 questions separated by newlines. No numbering.\n",
        "        \"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    questions = [q.strip() for q in response.text.strip().split('\\n') if q.strip()]\n",
        "    return questions[:3]\n",
        "\n",
        "def step_2_get_responses(questions):\n",
        "    \"\"\"Retrieves short responses (Max 1 result per question).\"\"\"\n",
        "    print(f\"Step 2: Retrieving short responses from the web...\")\n",
        "    q_and_a_results = []\n",
        "\n",
        "    for i, q in enumerate(questions, 1):\n",
        "        print(f\"   {i}. Searching: {q}\")\n",
        "        try:\n",
        "            # max_results=1 forces a short response\n",
        "            search_result = tavily.search(query=q, search_depth=\"basic\", max_results=1)\n",
        "\n",
        "            if search_result['results']:\n",
        "                content = search_result['results'][0]['content'][:600] # Limit char count\n",
        "                q_and_a_results.append(f\"Question: {q}\\nFound Info: {content}\")\n",
        "            else:\n",
        "                q_and_a_results.append(f\"Question: {q}\\nFound Info: No data.\")\n",
        "        except:\n",
        "             q_and_a_results.append(f\"Question: {q}\\nFound Info: Search Failed.\")\n",
        "\n",
        "    return \"\\n---\\n\".join(q_and_a_results)\n",
        "\n",
        "def step_3_summarize(input_text, research_data, mode):\n",
        "    prompt = f\"Summarize user input '{input_text[:5000]}' combined with search data '{research_data}' into a Markdown report.\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "v8KT9iDKZMaG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MAIN LOOP ---\n",
        "\n",
        "def main():\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\"*15 + \" STRICT HYBRID AGENT \" + \"=\"*15)\n",
        "        print(\"1. Research a Topic (Text ðŸ’¬)\")\n",
        "        print(\"2. Research a Paper (Upload PDF ðŸ“–)\")\n",
        "        print(\"3. View History ðŸ“œ\")\n",
        "        print(\"4. Exit ðŸ“¤\")\n",
        "\n",
        "        choice = input(\"Select Option: \")\n",
        "\n",
        "        if choice == '4':\n",
        "            print(\"Goodbye.ðŸ‘‹\")\n",
        "            break\n",
        "\n",
        "        # --- OPTION 3: HISTORY ---\n",
        "        if choice == '3':\n",
        "            history_data = memory.show_history()\n",
        "            if history_data:\n",
        "                sub_choice = input(\"\\nEnter ID to view full report (or Press Enter to go back): \")\n",
        "                if sub_choice.isdigit():\n",
        "                    idx = int(sub_choice) - 1\n",
        "                    if 0 <= idx < len(history_data):\n",
        "                        entry = history_data[idx]\n",
        "                        print(f\"\\nðŸ” RECALLING REPORT FOR: {entry['input']}\")\n",
        "                        print(\"-\" * 50)\n",
        "                        display(Markdown(entry['report']))\n",
        "                        input(\"\\nPress Enter to continue...\")\n",
        "            continue # Skip the rest and go back to menu\n",
        "\n",
        "        # SETUP INPUT\n",
        "        mode = \"\"\n",
        "        input_data = \"\"\n",
        "        label = \"\" # Used for history title\n",
        "\n",
        "        if choice == '1':\n",
        "            mode = \"topic\"\n",
        "            input_data = input(\"\\nEnter Research Topic: \")\n",
        "            label = input_data\n",
        "\n",
        "        elif choice == '2':\n",
        "            mode = \"pdf\"\n",
        "            print(\"\\nâ¬†ï¸ Upload PDF now:\")\n",
        "            uploaded = files.upload()\n",
        "            if uploaded:\n",
        "                filename = next(iter(uploaded))\n",
        "                input_data = extract_pdf_text(uploaded[filename])\n",
        "                label = f\"PDF: {filename}\"\n",
        "            else:\n",
        "                print(\"No file uploaded.\")\n",
        "                continue\n",
        "\n",
        "        if input_data:\n",
        "            # --- EXECUTE 3-STEP PROCESS ---\n",
        "\n",
        "            # 1. Generate Questions\n",
        "            questions = step_1_generate_questions(input_data, mode)\n",
        "            print(f\"   -> Plan: {questions}\")\n",
        "\n",
        "            # 2. Retrieve Responses\n",
        "            raw_data = step_2_get_responses(questions)\n",
        "\n",
        "            # 3. Summarize\n",
        "            final_report = step_3_summarize(input_data, raw_data, mode)\n",
        "\n",
        "            print(\"\\n\" + \"=\"*20 + \" ðŸŽ¯ FINAL REPORT: \" + \"=\"*20 + \"\\n\")\n",
        "            display(Markdown(final_report))\n",
        "\n",
        "            # Save to History\n",
        "            memory.save_entry(label, mode, final_report)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vo-ADx9UaIxX",
        "outputId": "96704503-a9d6-4503-b792-e864664584b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=============== STRICT HYBRID AGENT ===============\n",
            "1. Research a Topic (Text ðŸ’¬)\n",
            "2. Research a Paper (Upload PDF ðŸ“–)\n",
            "3. View History ðŸ“œ\n",
            "4. Exit ðŸ“¤\n",
            "Select Option: 3\n",
            "\n",
            "ðŸ“­ History is empty.\n",
            "\n",
            "=============== STRICT HYBRID AGENT ===============\n",
            "1. Research a Topic (Text ðŸ’¬)\n",
            "2. Research a Paper (Upload PDF ðŸ“–)\n",
            "3. View History ðŸ“œ\n",
            "4. Exit ðŸ“¤\n",
            "Select Option: 1\n",
            "\n",
            "Enter Research Topic: Ocular Toxoplasmosis\n",
            "\n",
            "Step 1: Generating 3 sub-questions (Mode: topic)...\n",
            "   -> Plan: ['What are the causes and symptoms of ocular toxoplasmosis?', 'How is ocular toxoplasmosis diagnosed and treated?', 'What are the long-term complications and prevention strategies for ocular toxoplasmosis?']\n",
            "Step 2: Retrieving short responses from the web...\n",
            "   1. Searching: What are the causes and symptoms of ocular toxoplasmosis?\n",
            "   2. Searching: How is ocular toxoplasmosis diagnosed and treated?\n",
            "   3. Searching: What are the long-term complications and prevention strategies for ocular toxoplasmosis?\n",
            "\n",
            "==================== ðŸŽ¯ FINAL REPORT: ====================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ocular Toxoplasmosis\n\n## Causes\nOcular toxoplasmosis is a disease caused by an infection with the parasite *Toxoplasma gondii*. The infection can be acquired congenitally (at birth) or postnatally, with postnatal infection now considered the more common cause.\n\n## Symptoms and Clinical Features\nThe diagnosis is primarily made through clinical observation of characteristic eye lesions. Key signs and symptoms include:\n*   Blurred vision\n*   Focal necrotizing retinochoroiditis (inflammation and tissue death in the retina and choroid)\n*   Retinal scars from past inflammation\n*   Segmental retinal arteritis with Kyrieleis plaques (in atypical cases)\n\n## Diagnosis\nDiagnosis is mainly based on a clinical eye examination that reveals a focal necrotizing retinochoroiditis. It is important to note that an immunosuppressed patient may have an active ocular toxoplasmosis infection even with completely negative immunoglobulin titers.\n\n## Treatment and Prevention\nTreatment is available for both immunocompetent and immunocompromised patients. To prevent the disease from recurring, long-term prophylactic treatment with a combination of trimethoprim and sulfamethoxazole may be recommended. The American Academy of Ophthalmology has reported evidence supporting this approach to reduce recurrences."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Research saved to History.\n",
            "\n",
            "=============== STRICT HYBRID AGENT ===============\n",
            "1. Research a Topic (Text ðŸ’¬)\n",
            "2. Research a Paper (Upload PDF ðŸ“–)\n",
            "3. View History ðŸ“œ\n",
            "4. Exit ðŸ“¤\n",
            "Select Option: 4\n",
            "Goodbye.ðŸ‘‹\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CGqYOeTPaNAV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}